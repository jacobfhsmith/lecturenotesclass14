---
title: "Simulation-based inference - hypothesis testing"
author: ""
date: ""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE,
                      comment = "#>", highlight = TRUE,
                      fig.align = "center")
```

## Main ideas

- Understand the hypothesis testing framework

- Understand the statistical conclusions that can and cannot be made from a
  hypothesis test
  
- Use functions from `infer` to carry-out a simulation-based hypothesis test
  for the population mean and population proportion
  
# Packages

```{r packages}
library(tidyverse)
library(infer)
```

# Recall

## Terminology

**Population**: a group of individuals or objects we are interested in 
studying

**Parameter**: a numerical quantity derived from the population
(almost always unknown)

**Sample**: a subset of our population of interest

**Statistic**: a numerical quantity derived from a sample
  
Common population parameters of interest and their corresponding
sample statistic:


| Quantity           | Parameter  | Statistic   |
|--------------------|------------|-------------|
| Mean               | $\mu$      | $\bar{x}$   |
| Variance           | $\sigma^2$ | $s^2$       |
| Standard deviation | $\sigma$   | $s$         |
| Median             | $M$        | $\tilde{x}$ |
| Proportion         | $p$        | $\hat{p}$   |


## Statistical inference

**Statistical inference** is the process of using sample data to make 
  conclusions about the underlying population the sample came from.

**Estimation**: estimating an unknown parameter based on values from the
  sample at hand

**Testing**: evaluating whether our observed sample provides evidence 
  for or against some claim about the population

We will now move to testing hypotheses.

# Testing

## How can we answer research questions using statistics?

**Statistical hypothesis testing** is the procedure that assesses
evidence provided by the data in favor of or against some claim
about the population (often about a population parameter or
potential associations).

Example:

The state of North Carolina claims that students in 8th grade are spending, on
average, 200 minutes on Zoom each day. *What do you make of this statement?*
*How would you evaluate the veracity of the claim?*

## The hypothesis testing framework

1. Start with two hypotheses about the population: the null hypothesis and the alternative hypothesis.

2. Choose a (representative) sample, collect data, and analyze the data.

3. Figure out how likely it is to see data like what we observed, **IF** the 
   null hypothesis were in fact true.

4. If our data would have been extremely unlikely if the null claim were true, then we reject it and deem the alternative claim worthy of further study. Otherwise, we cannot reject the null claim.

## Two competing hypotheses

The **null hypothesis** (often denoted $H_0$) states that "nothing unusual 
is happening" or "there is no relationship," etc.

On the other hand, the **alternative hypothesis** 
(often denoted $H_1$ or $H_A$) states the opposite: that there is some sort of relationship (usually this is what we want to check or really think is 
happening).

In statistical hypothesis testing we always first assume that the null 
hypothesis is true and then see whether we reject or fail to reject this claim.

## 1. Defining the hypotheses

The null and alternative hypotheses are defined for **parameters,** not 
statistics.

What will our null and alternative hypotheses be for this example?

- $H_0$: the true mean time spent on Zoom per day for 8th grade students is
  200 minutes
- $H_1$: the true mean time spent on Zoom per day for 8th grade students is not
  200 minutes

Expressed in symbols:

- $H_0: \mu = 200$
- $H_1: \mu \neq 200$,

where $\mu$ is the true population mean time spent on Zoom per day by 8th grade North Carolina students.

## 2. Collecting and summarizing data

With these two hypotheses, we now take our sample and summarize the data.

```{r}
zoom_time <- c(299, 192, 196, 218, 194, 250, 183, 218, 207, 
               209, 191, 189, 244, 233, 208, 216, 178, 209, 
               201, 173, 186, 209, 188, 231, 195, 200, 190, 
               199, 226, 238)
```

```{r}
mean(zoom_time)
```

The choice of summary statistic calculated depends on the type of data. In our 
example, we use the sample mean: $\bar{x} = 209$.

Do you think this is enough evidence to conclude that the mean time is not
200 minutes?

## 3. Assessing the evidence observed

Next, we calculate the probability of getting data like ours, *or more extreme*, 
if $H_0$ were in fact actually true.

This is a conditional probability: 
Given that $H_0$ is true (i.e., if $\mu$ were *actually* 200), what would be the probability of observing $\bar{x} = 209$?" This probability is known as the **p-value**.

## 4. Making a conclusion

We reject the null hypothesis if this conditional probability is small enough.

If it is very unlikely to observe our data (or more extreme) if $H_0$ were 
actually true, then that might give us enough evidence to suggest that it is
actually false (and that $H_1$ is true).

What is "small enough"? 

- We often consider a numeric cutpoint **significance level** defined 
  *prior* to conducting the analysis.
  
- Many analyses use $\alpha = 0.05$. This means that if $H_0$ were in fact true, we would expect to make the wrong decision only 5% of the time. 

## What can we conclude?

Case 1: $\mbox{p-value} \ge \alpha$:

If the p-value is $\alpha$ or greater, we say the results are not statistically significant and we **fail to reject** $H_0$. 

Importantly, **we never "accept" the null hypothesis** -- we performed the 
analysis assuming that $H_0$ was true to begin with and assessed the probability  of seeing our observed data or more extreme under this assumption.

Case 2: $\mbox{p-value} < \alpha$

If the p-value is less than $\alpha$, we say the results are **statistically significant**. In this case, we would make the decision to **reject the null hypothesis**.

Similarly, **we never "accept" the alternative hypothesis**.

## What is a p-value?

"The **p-value** is the probability of observing data at least as favorable to the alternative hypothesis as our current data set, if the null hypothesis were true. We typically use a summary statistic of the data, in this section the sample proportion, to help compute the p-value and evaluate the hypotheses." (Open Intro Stats, pg. 194)

## What **isn't** a p-value?

- "A p-value of 0.05 means the null hypothesis has a probability of only 5% of* being true.

- "A p-value of 0.05 means there is a 95% chance or greater that the null *hypothesis is incorrect"* 

p-values do **not** provide information on the probability that the null 
hypothesis is true given our observed data.

Again, a p-value is calculated *assuming* that $H_0$ is true. It cannot be 
used to tell us how likely that assumption is correct. When we fail to reject 
the null hypothesis, we are stating that there is **insufficient evidence** to 
assert that it is false. This could be because...

- ... $H_0$ actually *is* true!

- ... $H_0$ is false, but we got unlucky and happened to get a sample that 
didn't give us enough reason to say that $H_0$ was false

Even more bad news, hypothesis testing does NOT give us the tools to 
determine which one of the two scenarios occurred.

## What can go wrong?

Suppose we test a certain null hypothesis, which can be either true or false 
(we never know for sure!). We make one of two decisions given our data: either 
reject or fail to reject $H_0$. 


We have the following four scenarios:

| Decision             | $H_0$ is true    | $H_0$ is false   |
|----------------------|------------------|------------------|
| Fail to reject $H_0$ | Correct decision | *Type II Error*  |
| Reject $H_0$         | *Type I Error*   | Correct decision |

It is important to weigh the consequences of making each type of error.

In fact, $\alpha$ is precisely the probability of making a Type I error. We will talk about this (and the associated probability of making a Type II error) in future lectures.

## Let's conduct some hypothesis tests
# Data

We'll continue to work with the sample of Zoom screen-time data we obtained.
To make things easier with the `infer` functions, we'll create a tibble with
`time` as a single variable.

```{r zoom_data}
zoom <- tibble(
  time = c(299, 192, 196, 218, 194, 250, 183, 218, 207, 
           209, 191, 189, 244, 233, 208, 216, 178, 209, 
           201, 173, 186, 209, 188, 231, 195, 200, 190, 
           199, 226, 238))
```

```{r preview_zoom}
zoom
```

# Set seed

To obtain reproducible results, set the seed for the random number generation.

```{r set_seed}
set.seed(1421)
```

# Notes

Recall our hypothesis testing framework:

1. Start with two hypotheses about the population: the null hypothesis and the 
   alternative hypothesis.

2. Choose a (representative) sample, collect data, and analyze the data.

3. Figure out how likely it is to see data like what we observed, **IF** the 
   null hypothesis were in fact true.

4. If our data would have been extremely unlikely if the null claim were true, 
   then we reject it and deem the alternative claim worthy of further study. 
   Otherwise, we cannot reject the null claim.
   
## Example: testing population mean - $\mu$
   
We've already done items 1 and 2, where

$$H_0: \mu = 200$$
$$H_1: \mu \neq 200$$

For this study, let $\alpha = 0.05$. 

To tackle items 3 and 4, we'll use a simulation-based approach with functions
from `infer`.

### Simulate the null distribution

Recall that there is variability in the sampling distribution of the sample
mean. We need to account for this in our statistical study. Just as we did
for confidence intervals, we'll use a bootstrap procedure here.

1. `specify()` the variable of interest

2. set the null hypothesis with `hypothesize()`

3. `generate()` the bootstrap samples

4. `calculate()` the statistic of interest

```{r zoom_null}
null_dist <- zoom %>% 
  specify(response = time) %>% 
  hypothesize(null = "point", mu = 200) %>% 
  generate(reps = 10000, type = "bootstrap") %>% 
  calculate(stat = "mean")
```

### Visualize the null distribution

```{r zoom_null_viz}
visualise(null_dist) +
  labs(x = "Sample means", y = "Count", title = "Simulated null distribution")
```

**What do you notice?**

### Compute p-value

Next, we calculate the probability of getting data like ours, *or more extreme*,
if $H_0$ were in fact actually true.

Our observed sample mean is 209 minutes.

```{r zoom_xbar}
x_bar <- zoom %>% 
  summarise(mean_time = mean(time))
x_bar
```

```{r zoom_null_viz_pvalue}
visualise(null_dist) +
  shade_p_value(obs_stat = x_bar, direction = "two-sided") +
  labs(x = "Sample mean", y = "Count")
```

In the context of this simulation-based approach, the p-value is the proportion
of observations shaded light-red. To compute this, `infer` provides a 
convenient function -- `get_p_value()`.

```{r zoom_pvalue}
null_dist %>% 
  get_p_value(obs_stat = x_bar, direction = "two-sided")
```

### Conclusion

Given the calculated p-value and the specified $\alpha$, what conclusion do 
you make?

## Practice 1

Recall our original example: The state of North Carolina claims that students in
8th grade are spending, on average, 200 minutes on Zoom each day. Suppose in
reporting this the incorrect metric was specified, it should have been the
median time. Use your sample data to investigate if the median Zoom screen-time
is more than 200 minutes.

(1) Write out the hypotheses for this statistical test. Let $M$ represent the
    population median. Let $\alpha = 0.05$.
    
(2) Generate the null distribution.

```{r practice_1_2}

```

(3) Visualize the null distribution, observed statistic, and shaded region
    corresponding to the p-value.
    
```{r practice_1_3}

```

(4) Interpret the results of your test in the context of the data.

```{r practice_1_4}

```

## Example: testing population proportion - $p$

People providing an organ for donation sometimes seek the help of a special 
medical consultant. These consultants assist the patient in all aspects of the
surgery, with the goal of reducing the possibility of complications during the 
medical procedure and recovery. Patients might choose a consultant based in 
part on the historical complication rate of the consultant's clients.

One consultant tried to attract patients by noting that the average complication 
rate for liver donor surgeries in the US is about 10%, but her clients have 
only had 3 complications in the 62 liver donor surgeries she has facilitated. 
She claims this is strong evidence that her work meaningfully contributes to 
reducing complications (and therefore she should be hired!).

(1) Write out the hypotheses for this statistical test. Let $p$ represent the
    population proportion of complications from liver donor surgeries. State
    your significance level.
    
    $$H_0: p = 0.10$$
    $$H_A: p < 0.10$$
    
    Let $\alpha = 0.01$.
    
(2) Generate the null distribution.

```{r liver_data}
liver <- tibble(
  surgery_result = rep(c("complication", "no complication"), times = c(3, 59))
)
liver
```

```{r liver_null}
null_dist_phat <- liver %>% 
  specify(response = surgery_result, success = "complication") %>% 
  hypothesise(null = "point", p = 0.10) %>% 
  generate(reps = 1000) %>% 
  calculate(stat = "prop")
```

(3) Visualize the null distribution, observed statistic, and shaded region
    corresponding to the p-value.
    
```{r liver_null_viz}
p_hat <- liver %>% 
  count(surgery_result) %>% 
  mutate(prop = n / sum(n)) %>% 
  filter(surgery_result == "complication") %>% 
  select(prop)
visualise(null_dist_phat) +
  shade_p_value(obs_stat = p_hat, direction = "less") +
  labs(x = "Sample proportion", y = "Count")
```

(4) Interpret the results of your test in the context of the data.

```{r liver_pvalue}
null_dist_phat %>% 
  get_p_value(obs_stat = p_hat, direction = "less")
```

## Practice 2

Consider the mice data from the previous notes.

```{r data_mice}
mice <- read_table("http://users.stat.ufl.edu/~winner/data/micerad.dat",
                   col_names = FALSE) %>% 
  rename(dose = X1, treat = X2, died = X3)
```

Previous studies have shown that 50% of mice die when subject to radiation
despite being on a treatment. Does the Streptomycin Therapy 
(treatment in this study) produce a survival rate better than 50%? Perform
a statistical hypothesis test to investigate. State the hypotheses,
significance level, p-value, and conclusion. What is a hidden variable we
are not considering when conducting this test?

$$H_0: p = 0.50$$
$$H_A: p < 0.50$$

Let $\alpha = 0.01$.

First, we'll compute the observed sample proportion of mice that died while
on the treatment.

```{r mice_p_hat}

```

```{r mice_test}

```

Given that the p-value is less than $\alpha$ we reject the null hypothesis.
That is, we reject the claim that the survival rate of mice exposed to radiation
while on the Streptomycin Therapy is 50%.

A hidden variable we haven't accounted for and assumed to be constant was the
radiation `dose`. In our example, this is okay because our main focus is 
understanding the testing framework. However, in practice, it would be bad
to not consider this in an analysis.

## References

1. C.W. Hammond, et al. (1955). "The Effect of Streptomycin Therapy
   on Mice Irradiated with Fast Neutrons", Radiation Research, Vol2,#4,
   pp.354-360

2. "Infer - Tidy Statistical Inference". Infer.Netlify.App, 2021, 
   https://infer.netlify.app/index.html.